Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job stats:
job                  count
-----------------  -------
write_model_input        1
total                    1

Select jobs to execute...

[Sat Oct  5 17:22:45 2024]
rule write_model_input:
    input: /projects/0/einf4705/workflow/output/ss_test/gswp3-w5e5/ss/slurm_logs/2_write_model_input/write_model_input_setup_complete
    output: /projects/0/einf4705/workflow/output/ss_test/gswp3-w5e5/ss/slurm_logs/2_write_model_input/_writeModels_ss_complete
    jobid: 0
    reason: Forced execution
    resources: tmpdir=/scratch-local/bvjaarsv.8087992

Submitted batch job 8087997
slurmstepd: error: *** JOB 8087992 ON tcn547 CANCELLED AT 2024-10-05T17:32:51 ***

JOB STATISTICS
==============
Job ID: 8087992
Cluster: snellius
User/Group: bvjaarsv/bvjaarsv
State: CANCELLED (exit code 0)
Nodes: 1
Cores per node: 16
CPU Utilized: 00:00:01
CPU Efficiency: 0.01% of 02:47:28 core-walltime
Job Wall-clock time: 00:10:28
Memory Utilized: 121.47 MB
Memory Efficiency: 0.42% of 28.00 GB
